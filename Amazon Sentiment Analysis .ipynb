{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![title](amazon.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Amazon reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![title](senti.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a list of over 1,500 consumer reviews for Amazon products like the Kindle, Fire TV Stick, and more provided by Datafiniti's Product Database. The dataset includes basic product information, rating, review text, and more for each product. The Kaggle's link to the [dataset](https://www.kaggle.com/datafiniti/consumer-reviews-of-amazon-products/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  EDA and Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries pandas and numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and rename the reviews,title and rating coulmns.Also we have considered only these three columns going ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "data = pd.read_csv(\"Amazon_reviews.csv\")\n",
    "data = data[[\"reviews.text\",\"reviews.title\",\"reviews.rating\"]]\n",
    "data.columns = [\"review\",\"title\",\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I initially had trouble deciding between the p...</td>\n",
       "      <td>Paperwhite voyage, no regrets!</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allow me to preface this with a little history...</td>\n",
       "      <td>One Simply Could Not Ask For More</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...</td>\n",
       "      <td>Great for those that just want an e-reader</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I bought one of the first Paperwhites and have...</td>\n",
       "      <td>Love / Hate relationship</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have to say upfront - I don't like coroporat...</td>\n",
       "      <td>I LOVE IT</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Had older model, that you could text to speech...</td>\n",
       "      <td>Liked the smaller size</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This is a review of the Kindle Paperwhite laun...</td>\n",
       "      <td>Superb reading device - but which one's best f...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I love my kindle! I got one for my fiance on h...</td>\n",
       "      <td>I love it!</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Vraiment bon petit appareil , lger et facile d...</td>\n",
       "      <td>Un plaisir</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Exactly what it is supposed to be. Works great...</td>\n",
       "      <td>Works great and I love the built-in light</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  \\\n",
       "0   I initially had trouble deciding between the p...   \n",
       "1   Allow me to preface this with a little history...   \n",
       "2   I am enjoying it so far. Great for reading. Ha...   \n",
       "3   I bought one of the first Paperwhites and have...   \n",
       "4   I have to say upfront - I don't like coroporat...   \n",
       "13  Had older model, that you could text to speech...   \n",
       "14  This is a review of the Kindle Paperwhite laun...   \n",
       "15  I love my kindle! I got one for my fiance on h...   \n",
       "16  Vraiment bon petit appareil , lger et facile d...   \n",
       "17  Exactly what it is supposed to be. Works great...   \n",
       "\n",
       "                                                title  rating  \n",
       "0                      Paperwhite voyage, no regrets!     5.0  \n",
       "1                   One Simply Could Not Ask For More     5.0  \n",
       "2          Great for those that just want an e-reader     4.0  \n",
       "3                            Love / Hate relationship     5.0  \n",
       "4                                           I LOVE IT     5.0  \n",
       "13                             Liked the smaller size     4.0  \n",
       "14  Superb reading device - but which one's best f...     5.0  \n",
       "15                                         I love it!     5.0  \n",
       "16                                         Un plaisir     4.0  \n",
       "17          Works great and I love the built-in light     5.0  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing rows with no rating\n",
    "data = data[~data.rating.isnull()]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new Label to classify ratings as positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Label\n",
    "data[\"label\"] = 0\n",
    "data.loc[data[\"rating\"]>3,\"label\"] = 1\n",
    "\n",
    "#Delete the \"rating\" column \n",
    "del data[\"rating\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    977\n",
       "0    200\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the output, there are more positive ratings in contrast to negative ratings. In order to avoid bias, we shall consider only 200 positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 3)\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([data[data.label==1][:200],data[data.label==0]])\n",
    "data = data.sample(frac=1)\n",
    "print(data.shape)\n",
    "#print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into training and test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 3) (120, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data,test_size=0.3, random_state=42)\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to create dictionary for the positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "from scipy.sparse import csr_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bing_lex_feat(data):\n",
    "    negList = []\n",
    "    posList = []\n",
    "    wordDict = dict()\n",
    "\n",
    "    with open('positive-words.txt', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        headerRows = [i for i in range(0, 35)]\n",
    "        for row in headerRows:\n",
    "            next(reader)\n",
    "        for word in reader:\n",
    "            posList.extend(word[0])\n",
    "            wordDict[word[0]] = 'positive'\n",
    "\n",
    "        # FYI, I had to edit the word 'inimically' in the original file as there was a weird non utf-8 character\n",
    "    with open('negative-words.txt', 'r',encoding='latin') as f:\n",
    "        reader = csv.reader(f)\n",
    "        headerRows = [i for i in range(0, 35)]\n",
    "        for row in headerRows:\n",
    "            next(reader)\n",
    "        for word in reader:\n",
    "            negList.extend(word[0])\n",
    "            wordDict[word[0]] = 'negative'\n",
    "            \n",
    "    def calc_it(review):\n",
    "        tokens = nltk.tokenize.word_tokenize(review)\n",
    "        counts = {'positive':0,'negative':0}\n",
    "        for token in tokens:\n",
    "            try:\n",
    "                counts[wordDict[token]] += 1\n",
    "            except:\n",
    "                pass\n",
    "        return counts\n",
    "        \n",
    "    data = data.apply(calc_it)\n",
    "    return csr_matrix(pd.concat([data.apply(lambda x: x[\"positive\"]),data.apply(lambda x: x[\"negative\"])],axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 3634)\n",
      "(280, 3634)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train.review)\n",
    "print(X_train_counts.shape)\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "print( X_train_tf.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting all features from the documents and assigning unique values.It also give the counts of positive or negative words in a review Normalized using TfidfTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 3636)\n"
     ]
    }
   ],
   "source": [
    "train_lex_dict_feat = bing_lex_feat(train.review)\n",
    "train_feat = hstack([X_train_tf,train_lex_dict_feat])\n",
    "#print(X_train_tf)\n",
    "#print(train_lex_dict_feat)\n",
    "#print(train_feat)\n",
    "print(train_feat.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applied the defined function on training data. Used Hstack to concatenate the outputs of CountVectorizer and TfidTransformer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0\n",
      " 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0\n",
      " 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 0 1 1 1]\n",
      "Accuracy Of RandomForest: 0.466666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier().fit(train_feat, train.label)\n",
    "\n",
    "X_test_counts = count_vect.transform(test.review)\n",
    "X_test_tf = tf_transformer.transform(X_test_counts)\n",
    "test_lex_dict_feat = bing_lex_feat(test.review)\n",
    "test_feat = hstack([X_test_tf,test_lex_dict_feat])\n",
    "\n",
    "predicted1 = clf.predict(test_feat)\n",
    "print (predicted)\n",
    "\n",
    "print(\"Accuracy Of RandomForest:\",np.mean(predicted==test.label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanke\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0\n",
      " 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0\n",
      " 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 0 1 1 1]\n",
      "Accuracy Of SGDC: 0.6\n"
     ]
    }
   ],
   "source": [
    "clf2 = SGDClassifier().fit(train_feat, train.label)\n",
    "\n",
    "X_test_counts = count_vect.transform(test.review)\n",
    "X_test_tf = tf_transformer.transform(X_test_counts)\n",
    "test_lex_dict_feat = bing_lex_feat(test.review)\n",
    "test_feat = hstack([X_test_tf,test_lex_dict_feat])\n",
    "\n",
    "predicted2 = clf2.predict(test_feat)\n",
    "print (predicted)\n",
    "\n",
    "print(\"Accuracy Of SGDC:\",np.mean(predicted2==test.label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0\n",
      " 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0\n",
      " 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 0 1 1 1]\n",
      "Accuracy Of Naive Bayes: 0.775\n"
     ]
    }
   ],
   "source": [
    "clf3 = MultinomialNB().fit(train_feat, train.label)\n",
    "\n",
    "X_test_counts = count_vect.transform(test.review)\n",
    "X_test_tf = tf_transformer.transform(X_test_counts)\n",
    "test_lex_dict_feat = bing_lex_feat(test.review)\n",
    "test_feat = hstack([X_test_tf,test_lex_dict_feat])\n",
    "\n",
    "predicted3 = clf3.predict(test_feat)\n",
    "print (predicted)\n",
    "\n",
    "print(\"Accuracy Of Naive Bayes:\",np.mean(predicted3==test.label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the given random_state we found that Multinomial Naive Bayes gave better accuracy. Let explore more using the metrics function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.63      0.74        60\n",
      "          1       0.71      0.92      0.80        60\n",
      "\n",
      "avg / total       0.80      0.78      0.77       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(test.label, predicted3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score can be interpreted as a weighted average of the precision and recall. Our model gave a f1-score of 0.82 which is a good measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * From our model we found that there are more positive reviews compared to negative ones for different products and services offered by Amazon.\n",
    " * We found thst for the past two years the sentiment of customers towards Amazon,its products and services is positive.\n",
    " * Our model works well for any Business who wants to evaluate their products. Since our dataset had reviews for different products, running this model on one product would help the product manager to get better insights on how is it performing in the market.  \n",
    " * This project utilizes unigram model but also has a scope for using bigram "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * There are situations when the feedback for a product is given only in terms of reviews and not ratings. Even in social media like Twitter,Facebook etc. where customers give reviews its difficult for a Product Manager to know which reviews were good or bad. It gets cumbersome to look into all the reviews to understand how certain subject is doing in the market.\n",
    " *   Sentiment analysis here plays an integral role to understand the customer experience and suggest suitable or optimal solutions for business.\n",
    " * Future scope for this project involves further classifying the emotions as angry, excited etc through more feature extractoin methods.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Opinion Lexicon: A list of [English](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html) positive and negative opinion words or sentiment words (around 6800 words). This list was compiled by Hu and Liu, KDD in 2004.\n",
    "Link - https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\n",
    "\n",
    "2.Feature Extraction (Count Vectorizer and Tfid Transformer) - http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiled By :\n",
    "Sanketh Bhagavanthi,\n",
    "Shahshidhar Channabasavaraj,\n",
    "Vinay Murthy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
